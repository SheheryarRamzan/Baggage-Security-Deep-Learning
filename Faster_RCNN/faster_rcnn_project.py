# -*- coding: utf-8 -*-
"""Faster_RCNN_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y5XR6aHtpfacu20KayG1AX-ky6FXSEO-

## Clone the Repository
"""

!git clone https://github.com/sovit-123/fastercnn-pytorch-training-pipeline.git

# Commented out IPython magic to ensure Python compatibility.
# Enter the repo directory.
# %cd fastercnn-pytorch-training-pipeline/

# Install the Requirements
!pip install -r requirements.txt

"""## Download the Dataset

Here we are using the [Aquarium Dataset](https://public.roboflow.com/object-detection/aquarium) from Roboflow.

Download the unzip the dataset to `custom_data` directory.
"""

!curl -L "https://universe.roboflow.com/ds/LCQNA858eV?key=dcGmfbKjWm" > roboflow.zip; unzip roboflow.zip -d custom_data; rm roboflow.zip

"""## Create the Custom Dataset YAML File."""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile data_configs/custom_data_Project.yaml
# # Images and labels direcotry should be relative to train.py
# TRAIN_DIR_IMAGES: 'custom_data/train'
# TRAIN_DIR_LABELS: 'custom_data/train'
# VALID_DIR_IMAGES: 'custom_data/valid'
# VALID_DIR_LABELS: 'custom_data/valid'
# 
# # Class names.
# CLASSES: [
#     '__background__',
#     'Gun', 'Knife', 'Pliers',
#     'Scissors', 'Wrench'
# ]
# 
# # Number of classes (object classes + 1 for background class in Faster RCNN).
# NC: 6
# 
# # Whether to save the predictions of the validation set while training.
# SAVE_VALID_PREDICTION_IMAGES: True

import yaml

file_path = 'data_configs/custom_data_Project.yaml'  # replace with your actual file path

with open(file_path, 'r') as file:
    data = yaml.safe_load(file)

print(data)

"""## Training"""

!python train.py --data data_configs/custom_data_Project.yaml --epochs 5 --model fasterrcnn_resnet50_fpn_v2 --name custom_training --batch 8

"""## Visualize Validation Results"""

import matplotlib.pyplot as plt
import glob as glob

results_dir_path = '/content/fastercnn-pytorch-training-pipeline/outputs/training/custom_training'
valid_images = glob.glob(f"{results_dir_path}/*.jpg")

print(len(valid_images))  # Print the length of valid_images

for i in range(3):
    plt.figure(figsize=(10, 7))
    image = plt.imread(valid_images[i])
    plt.imshow(image)
    plt.axis('off')
    plt.show()

"""Check Out the Repo for Latest Updates
https://github.com/sovit-123/fastercnn-pytorch-training-pipeline

## Evaluation
"""

# No verbose mAP.
!python eval.py --weights outputs/training/custom_training/best_model.pth --data data_configs/custom_data.yaml --model fasterrcnn_resnet50_fpn_v2

# Verbose mAP.
!python eval.py --weights outputs/training/custom_training/best_model.pth --data data_configs/custom_data.yaml --model fasterrcnn_resnet50_fpn_v2 --verbose