# -*- coding: utf-8 -*-
"""RetinaNet_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AH5CWSs3SO_P6XyASyhm1yq4-Yjq32pO
"""

!git clone https://github.com/fizyr/keras-retinanet.git

# Commented out IPython magic to ensure Python compatibility.
# %cd keras-retinanet/

!pip install .

!python setup.py build_ext --inplace

import os
import shutil
import zipfile
import urllib
import xml.etree.ElementTree as ET
import numpy as np
import csv
import pandas
from google.colab import drive
from google.colab import files

DATASET_DRIVEID = '1NFELQ2roA8ap9JCxo0OAbhvzs6BIEQEZ'

DATASET_DIR = 'dataset'
ANNOTATIONS_FILE = 'annotations.csv'
CLASSES_FILE = 'classes.csv'

import zipfile
from google.colab import drive

drive.mount('/content/drive/')

!unzip -u "/content/drive/My Drive/train.zip" -d "/content/drive/My Drive/dataset_retinanet"

import shutil

source_path = '/content/drive/My Drive/dataset_retinanet/train/_annotations.csv'
destination_path = '_annotations.csv'

shutil.copy(source_path, destination_path)

# Commented out IPython magic to ensure Python compatibility.
# %pwd

import pandas as pd

# Assuming the file is in the current working directory
file_path = '_annotations.csv'

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Display the DataFrame
print(df)

import pandas as pd

# Read the CSV file without header
df = pd.read_csv('_annotations.csv', header=None)

# Append the prefix to the first column
df.iloc[:, 0] = '/content/drive/My Drive/dataset_retinanet/train/' + df.iloc[:, 0].astype(str)

# Save the modified DataFrame back to a new CSV file
df.to_csv('modified.csv', index=False, header=None)

print(df)

import csv

data = [
    ('Knife',1),
    ('Wrench',2),
    ('Scissors',3),
    ('Pliers',4),
    ('Gun',5)
]

# Specify the file name
file_name = 'classes.csv'

# Write to CSV file
with open(file_name, 'w', newline='') as csv_file:
    writer = csv.writer(csv_file)
    writer.writerows(data)

print(f'The file {file_name} has been created with the specified contents.')

PRETRAINED_MODEL = './snapshots/_pretrained_model.h5'

#### OPTION 1: DOWNLOAD INITIAL PRETRAINED MODEL FROM FIZYR ####
URL_MODEL = 'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5'
urllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)

#### OPTION 2: DOWNLOAD CUSTOM PRETRAINED MODEL FROM GOOGLE DRIVE. CHANGE DRIVE_MODEL VALUE. USE THIS TO CONTINUE PREVIOUS TRAINING EPOCHS ####
#drive.mount('/content/gdrive')
#DRIVE_MODEL = '/content/gdrive/My Drive/Colab Notebooks/objdet_tensorflow_colab/resnet50_csv_10.h5'
#shutil.copy(DRIVE_MODEL, PRETRAINED_MODEL)


print('Downloaded pretrained model to ' + PRETRAINED_MODEL)

!keras_retinanet/bin/train.py --freeze-backbone --random-transform --weights {PRETRAINED_MODEL} --batch-size 8 --steps 500 --epochs 8 csv modified.csv classes.csv

# ### OPTIONAL: EXPORT TRAINED MODEL TO DRIVE ####
# drive.mount('/content/drive')
# COLAB_MODEL = './snapshots/resnet50_csv_10.h5'
# DRIVE_DIR = '/content/drive/My Drive/Colab Notebooks/objdet_tensorflow_colab/'
# shutil.copy(COLAB_MODEL, DRIVE_DIR)

# Commented out IPython magic to ensure Python compatibility.
# %pwd

# hypertune the model using lists for hyperparameters such as batch size, epochs, steps, etc.

# lists
batch_size = [8, 16, 32]
steps = [500, 1000, 2000]
epochs = [10, 20, 30]

# loop through lists
for batch in batch_size:
  for step in steps:
    for epoch in epochs:
      print('Training for batch size: {}, steps: {}, epochs: {}'.format(batch, step, epoch))
      !keras_retinanet/bin/train.py --freeze-backbone --random-transform --weights {PRETRAINED_MODEL} --batch-size {batch} --steps {step} --epochs {epoch} csv modified.csv classes.csv
      print('Training completed for batch size: {}, steps: {}, epochs: {}'.format(batch, step, epoch))

THRES_SCORE = 0.8

# Commented out IPython magic to ensure Python compatibility.
# show images inline
# %matplotlib inline

# automatically reload modules when they have changed
# %reload_ext autoreload
# %autoreload 2

# import keras
import keras

# import keras_retinanet
from keras_retinanet import models
from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image
from keras_retinanet.utils.visualization import draw_box, draw_caption
from keras_retinanet.utils.colors import label_color

# import miscellaneous modules
import matplotlib.pyplot as plt
import cv2
import os
import numpy as np
import time

# set tf backend to allow memory to grow, instead of claiming everything
import tensorflow as tf

def get_session():
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    return tf.Session(config=config)

# use this environment flag to change which GPU to use
#os.environ["CUDA_VISIBLE_DEVICES"] = "1"

# set the modified tf session as backend in keras
keras.backend.tensorflow_backend.set_session(get_session())

model_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[0])
print(model_path)

# load retinanet model
model = models.load_model(model_path, backbone_name='resnet50')
model = models.convert_model(model)

# load label to names mapping for visualization purposes
labels_to_names = pandas.read_csv('classes.csv',header=None).T.loc[0].to_dict()

def img_inference(img_path):
  image = read_image_bgr(img_infer)

  # copy to draw on
  draw = image.copy()
  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)

  # preprocess image for network
  image = preprocess_image(image)
  image, scale = resize_image(image)

  # process image
  start = time.time()
  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))
  print("processing time: ", time.time() - start)

  # correct for image scale
  boxes /= scale

  # visualize detections
  for box, score, label in zip(boxes[0], scores[0], labels[0]):
      # scores are sorted so we can break
      if score < THRES_SCORE:
          break

      color = label_color(label)

      b = box.astype(int)
      draw_box(draw, b, color=color)

      caption = "{} {:.3f}".format(labels_to_names[label], score)
      draw_caption(draw, b, caption)

  plt.figure(figsize=(10, 10))
  plt.axis('off')
  plt.imshow(draw)
  plt.show()

uploaded = files.upload()
img_infer = list(uploaded)[0]

print('Running inference on: ' + img_infer)
img_inference(img_infer)

# adjust this to point to your downloaded/trained model
# models can be downloaded here: https://github.com/fizyr/keras-retinanet/releases
model_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[0])
print(model_path)

# load retinanet model
model = models.load_model(model_path, backbone_name='resnet50')

# if the model is not converted to an inference model, use the line below
# see: https://github.com/fizyr/keras-retinanet#converting-a-training-model-to-inference-model
#model = models.convert_model(model)

#print(model.summary())
labels_to_names = {1: 'Knife', 2: 'Wrench', 3: 'Scissors', 4: 'Pliers', 5: 'Gun'}